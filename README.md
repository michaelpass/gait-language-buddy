# GAIT Language Buddy

GAIT Language Buddy is an AI-powered language-learning prototype built for the **Generative AI Tools (GAIT)** course project.  
This application guides a learner through a multimodal workflow:

1. A scene is generated (currently text-based; planned for image generation).  
2. The learner writes a description in their target language.  
3. The app evaluates the writing using an OpenAI model.  
4. A personalized mini-lesson is generated based on learner strengths/weaknesses.  
5. (Future) The app will produce audio examples and rich multimodal outputs.

The user interface is built using **PySimpleGUI** for rapid prototyping and easy team collaboration.

---

## âœ¨ Features

### âœ” Scene Generation (Text for Now)
- Provides a simple scene to describe.
- Will later integrate OpenAI image generation.

### âœ” LLM-Powered Writing Evaluation
- Detects grammar/vocabulary issues.
- Infers CEFR-style proficiency (A1â€“C2).
- Provides strengths, weaknesses, suggestions.

### âœ” LLM-Powered Mini-Lesson
- Tailored feedback based on the learnerâ€™s writing.
- Includes example sentences and vocabulary suggestions.

### âœ” Graceful Fallbacks
If the OpenAI API key is missing or a request fails:
- A rule-based evaluator is used.
- A rule-based mini-lesson is generated.

This ensures anyone (e.g., classmates) can run the app without an API key.

---

## ðŸ§± Project Structure
gait-language-buddy/
â”œâ”€ .env                  # Stores OPENAI_API_KEY (ignored by git)
â”œâ”€ .gitignore
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ main.py               # PySimpleGUI app controller
â””â”€ core/
â”œâ”€ init.py
â”œâ”€ models.py          # Data classes for structured outputs
â””â”€ api.py             # OpenAI-backed evaluation + mini-lesson logic

---

## ðŸ“¦ Getting Started

### 1. Clone the repository

```
git clone https://github.com/<your-username>/gait-language-buddy.git
cd gait-language-buddy
```

ðŸ–¥ Usage Guide
	1.	Choose your target language.
	2.	Click New Scene to load a description prompt.
	3.	Write your paragraph in the target language.
	4.	Click Evaluate Writing to receive:
	â€¢	proficiency level
	â€¢	strengths
	â€¢	weaknesses
	â€¢	suggestions
	â€¢	auto-generated mini-lesson
	5.	Click Generate Audio (stub; real TTS planned for Phase 2).

â¸»

ðŸ§ª Tech Stack
	â€¢	Python 3.10+
	â€¢	PySimpleGUI for the user interface
	â€¢	OpenAI API for evaluation and mini-lessons
	â€¢	python-dotenv for environment variable management

â¸»

ðŸ›  How the Code Works

core/models.py

Contains structured dataclasses:
	â€¢	TextAnalysis
	â€¢	MiniLesson
	â€¢	AudioInfo

core/api.py

Handles:
	â€¢	environment loading (os.getenv, load_dotenv)
	â€¢	OpenAI LLM calls
	â€¢	fallback heuristics when the API isnâ€™t available

main.py

Defines:
	â€¢	the GUI layout
	â€¢	GUI event loop
	â€¢	rendering logic for analysis, lessons, audio

â¸»

ðŸŒ± Planned Enhancements

Phase 2 (Multimodal)
	â€¢	Real image generation for scene creation
	â€¢	Real text-to-speech audio output
	â€¢	Learner speech input + pronunciation evaluation

Phase 3 (Intelligent Tutoring)
	â€¢	Learner profiles and progress tracking
	â€¢	Dynamic difficulty adjustment
	â€¢	Rubric-based CEFR scoring (A1â€“C2)
	â€¢	More advanced lesson generation

â¸»

ðŸ‘¥ Contributors
	â€¢	Michael Pass
  â€¢	Dani Perez
	â€¢	Mishka Mohamed Nour
  

â¸»

ðŸ“„ License

This project is currently for academic use within the GAIT course.
A standard license (MIT/GPL/etc.) may be added later based on team preference.

â¸»

ðŸŽ“ Instructor Notes (Optional Section)

This project is designed as a demonstration of:
	â€¢	multimodal LLM interactions
	â€¢	stateful evaluation over multiple steps
	â€¢	GUI-backed applications using OpenAI APIs
	â€¢	safe development patterns with fallbacks

â¸»

ðŸ™Œ Acknowledgments

Thanks to the GAIT course faculty for guidance and inspiration in applied multimodal AI.
